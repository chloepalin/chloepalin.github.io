# Using CNNs with large datasets

In today's post, I will be going through a step-by-step process to explain how to bulid a Convolutional Neural Network (CNN) that can classify images of cats or dogs. This is based on the Kaggle challenge that Jeremy presented in lesson 2, which you can find [here.](https://www.kaggle.com/competitions/dogs-vs-cats/overview/description). 

***<p style="text-align: center;">CNN's improve computer vision and accuracy with convolutions by building layers to enhance a neural network.</p>***

That sounds a bit too technical. Lets break it down.

CNNs are a type of AI model inspired by the human visual system, consisting of layers of interconnected artificial neurons. A convolution is a mathematical operation that combines two sets of information to produce a third set of information. In the context of CNNs, a convolution is used to process and extract features from an image. So in our case, imagine you have an image of a dog. In the first layer of a CNN, the network applies a set of small matricies filters to the image - this is convolution! Each filter is constructed in order to detect specific features, like as edges, textures, patterns, etc. The convolution operation involves sliding these filters over the image to then calculate a dot product between the filter and the local image patch it is currently on.

By applying different filters to an image, the CNN can learn to recognize various visual patterns and features. The output of the convolution operation is a feature map, which highlights the presence of certain features in the image. As the image passes through multiple layers of convolutions, each layer captures increasingly complex and abstract features. The early layers might identify simple edges or color gradients, while deeper layers could detect more complex shapes or specific objects. 

As such, now we can understand that the purpose of building layers in a CNN is to progressively enhance the network's ability to recongise and understand the content of an image. Each layer processes the input from the previous layer, which allows for higher-level feature extraction so you can learn any image!

## Importing libraries and data set
Before we start, its important that we import everything we will need to create our CNN. The full dataset is avaliable on the Kaggle website which can be downloaded for use in whatever deep learning set up you like best (personally, I have been enjoying Google Colab). Much of this CNN process will be done with `tensorflow` so libraries that will be useful include: 

```
import os
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
```

Once all of the data has been downloaded, prepare the data by unzipping the data into training and testing directories.

## Defining the CNN model

Now we can create our model! Our model will be a series of convolutional layers that have been max pooled.

```
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
]) 
model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])
```
[Source: Code supplied from Google Developers](https://developers.google.com/codelabs/tensorflow-6-largecnns#4).

The convolutional layers perform feature extraction by applying filters to the input images. The filters detect patterns and features in the images.
The maxpooling layers reduce the spatial dimensions of the feature maps obtained from the convolutional layers. They retain the most important information while reducing the computational complexity. The flatten layer converts the multidimensional feature maps into a 1D vector, preparing the data for the fully connected layers. Next, the dense layer learns all the complex relationships between the extracted features. We then get our output layer which is suitable for binary classification tasks (such as dog vs cat!). 

## Training the model

Now that we have our defined model, it is easy to train with `ImageDataGenerator`.

```
train_datagen = ImageDataGenerator(rescale=1.0/255.)
train_generator = train_datagen.flow_from_directory(TRAINING_DIR,
                                                    batch_size=100,
                                                    class_mode='binary',
                                                    target_size=(150, 150))
 
validation_datagen = ImageDataGenerator(rescale=1.0/255.)
validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,
                                                              batch_size=100,
                                                              class_mode='binary',
                                                              target_size=(150, 150))
                                                              
```
[Source: Code supplied from Google Developers](https://developers.google.com/codelabs/tensorflow-6-largecnns#4).

Then, we can use `model.fit_generator` from our generated trained and validated directories!

```
history = model.fit_generator(train_generator,
                              epochs=15,
                              verbose=1,
                              validation_data=validation_generator)
```

And there we have it! A CNN model that has been designed to work with overfitting large datasets!
TensorFlow and Machine Learning are great at helping with computer vision models.
