# Using CNNs with large datasets to avoid overfitting

In today's post, I will be going through a step-by-step process to explain how to bulid a Convolutional Neural Network (CNN) that can classify images of cats or dogs. This is based on the Kaggle challenge that Jeremy presented in lesson 2, which you can find [here.](https://www.kaggle.com/competitions/dogs-vs-cats/overview/description). 

***<p style="text-align: center;">CNN's improve computer vision and accuracy with convolutions by building layers to enhance a neural network.</p>***

That sounds a bit too technical. Lets break it down.

CNNs are a type of AI model inspired by the human visual system, consisting of layers of interconnected artificial neurons. A convolution is a mathematical operation that combines two sets of information to produce a third set of information. In the context of CNNs, a convolution is used to process and extract features from an image. So in our case, imagine you have an image of a dog. In the first layer of a CNN, the network applies a set of small matricies filters to the image - this is convolution! Each filter is constructed in order to detect specific features, like as edges, textures, patterns, etc. The convolution operation involves sliding these filters over the image to then calculate a dot product between the filter and the local image patch it is currently on.

By applying different filters to an image, the CNN can learn to recognize various visual patterns and features. The output of the convolution operation is a feature map, which highlights the presence of certain features in the image. As the image passes through multiple layers of convolutions, each layer captures increasingly complex and abstract features. The early layers might identify simple edges or color gradients, while deeper layers could detect more complex shapes or specific objects. 

As such, now we can understand that the purpose of building layers in a CNN is to progressively enhance the network's ability to recongise and understand the content of an image. Each layer processes the input from the previous layer, which allows for higher-level feature extraction so you can learn any image!

## Importing libraries and data set
Before we start, its important that we import everything we will need to create our CNN. The full dataset is avaliable on the Kaggle website which can be downloaded for use in whatever deep learning set up you like best (personally, I have been enjoying Google Colab). Much of this CNN process will be done with `tensorflow` so libraries that will be useful include: 

```
import os
import random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
```

Once all of the data has been downloaded, prepare the data by unzipping the data into training and testing directories.

## Defining the CNN model

```
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
]) 
model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])
```


